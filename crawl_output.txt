{"articles": [{"id": "2981549002", "title": "Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes.", "abstract": "Wide neural networks with random weights and biases are Gaussian processes, as originally observed by Neal (1995) and more recently by Lee et al. (2018) and Matthews et al. (2018) for deep fully-connected networks, as well as by Novak et al. (2019) and Garriga-Alonso et al. (2019) for deep convolutional networks. We show that this Neural Network-Gaussian Process correspondence surprisingly extends to all modern feedforward or recurrent neural networks composed of multilayer perceptron, RNNs (e.g. LSTMs, GRUs), (nD or graph) convolution, pooling, skip connection, attention, batch normalization, and/or layer normalization. More generally, we introduce a language for expressing neural network computations, and our result encompasses all such expressible neural networks. This work serves as a tutorial on the *tensor programs* technique formulated in Yang (2019) and elucidates the Gaussian Process results obtained there. We provide open-source implementations of the Gaussian Process kernels of simple RNN, GRU, transformer, and batchnorm+ReLU network at this http URL.", "date": "2019", "authors": ["Greg Yang"], "references": ["2194775991", "2949650786", "2963403868", "2963403868", "2626778328", "1836465849", "1836465849", "2949117887", "2964308564"]}, {"id": "3105081694", "title": "COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images.", "abstract": "The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors' knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors' knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most.", "date": "2020", "authors": ["Linda Wang", "Zhong Qiu Lin", "Alexander Wong"], "references": ["2194775991", "2949650786", "3001118548", "2962835968", "2962835968", "1686810756", "3008827533", "3008827533", "3005477624"]}, {"id": "2950893734", "title": "Self-Attention Generative Adversarial Networks", "abstract": "In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.", "date": "2018", "authors": ["Han Zhang", "Ian Goodfellow", "Dimitris Metaxas", "Augustus Odena"], "references": []}, {"id": "2194775991", "title": "Deep Residual Learning for Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.", "date": "2016", "authors": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "references": ["2618530766", "2163605009", "639708223", "639708223", "2613718673", "2953106684", "2963403868", "2963403868", "2626778328"]}, {"id": "2963403868", "title": "Attention is All You Need", "abstract": "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.", "date": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin"], "references": ["2963341956", "2896457183", "2965373594", "2970597249", "2970597249", "2950813464", "2963091558", "2963091558", "2770201307"]}, {"id": "2626778328", "title": "Attention Is All You Need", "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.", "date": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin"], "references": ["2963858333", "2766453196", "2963091558", "2963091558", "2770201307", "2907492528", "2963250244", "2963250244", "2885185669"]}, {"id": "1836465849", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.", "date": "2015", "authors": ["Sergey Ioffe", "Christian Szegedy"], "references": ["2194775991", "2949650786", "2963446712", "2963446712", "2511730936", "2183341477", "2183341477", "2949605076", "2302255633"]}, {"id": "2964308564", "title": "Neural Machine Translation by Jointly Learning to Align and Translate", "abstract": "Abstract: Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.", "date": "2014", "authors": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "references": ["2963403868", "2626778328", "2130942839", "2130942839", "2949888546", "1902237438", "1902237438", "2949335953", "1895577753"]}, {"id": "3001118548", "title": "Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China", "abstract": "A recent cluster of pneumonia cases in Wuhan, China, was caused by a novel betacoronavirus, the 2019 novel coronavirus (2019-nCoV). We report the epidemiological, clinical, laboratory, and radiological characteristics and treatment and clinical outcomes of these patients. All patients with suspected 2019-nCoV were admitted to a designated hospital in Wuhan. We prospectively collected and analysed data on patients with laboratory-confirmed 2019-nCoV infection by real-time RT-PCR and next-generation sequencing. Data were obtained with standardised data collection forms shared by the International Severe Acute Respiratory and Emerging Infection Consortium from electronic medical records. Researchers also directly communicated with patients or their families to ascertain epidemiological and symptom data. Outcomes were also compared between patients who had been admitted to the intensive care unit (ICU) and those who had not.", "date": "2020", "authors": ["Chaolin Huang", "Yeming Wang", "Xingwang Li", "Lili Ren", "Jianping Zhao", "Yi Hu", "Li Zhang", "Guohui Fan", "Jiuyang Xu", "Xiaoying Gu", "Zhenshun Cheng", "Ting Yu", "Jiaan Xia", "Yuan Wei", "Wenjuan Wu", "Xuelei Xie", "Wen Yin", "Hui Li", "Min Liu", "Yan Xiao", "Hong Gao", "Li Guo", "Jungang Xie", "Guangfa Wang", "Rongmeng Jiang", "Zhancheng Gao", "Qi Jin", "Jianwei Wang", "Bin Cao"], "references": []}, {"id": "2962835968", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "abstract": "Abstract: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.", "date": "2014", "authors": ["Karen Simonyan", "Andrew Zisserman"], "references": []}, {"id": "3008827533", "title": "Clinical Characteristics of Coronavirus Disease 2019 in China", "abstract": "Abstract Background Since December 2019, when coronavirus disease 2019 (Covid-19) emerged in Wuhan city and rapidly spread throughout China, data have been needed on the clinical characteristics of...", "date": "2020", "authors": ["Wei-Jie Guan", "Zheng-Yi Ni", "Yu Hu", "Wen-Hua Liang", "Chun-Quan Ou", "Jian-Xing He", "Lei Liu", "Hong Shan", "Chun-Liang Lei", "David S C Hui", "Bin Du", "Lan-Juan Li", "Guang Zeng", "Kwok-Yung Yuen", "Ru-Chong Chen", "Chun-Li Tang", "Tao Wang", "Ping-Yan Chen", "Jie Xiang", "Shi-Yue Li", "Jin-Lin Wang", "Zi-Jing Liang", "Yi-Xiang Peng", "Li Wei", "Yong Liu", "Ya-Hua Hu", "Peng Peng", "Jian-Ming Wang", "Ji-Yang Liu", "Zhong Chen", "Gang Li", "Zhi-Jian Zheng", "Shao-Qin Qiu", "Jie Luo", "Chang-Jiang Ye", "Shao-Yong Zhu", "Nan-Shan Zhong"], "references": ["3011508296", "3013967887", "3016127017", "3015863623", "3012756997", "3010951319", "3013215798", "3013215798", "3011466591"]}, {"id": "3005477624", "title": "Clinical characteristics of 2019 novel coronavirus infection in China", "abstract": "Background: Since December 2019, acute respiratory disease (ARD) due to 2019 novel coronavirus (2019-nCoV) emerged in Wuhan city and rapidly spread throughout China. We sought to delineate the clinical characteristics of these cases. Methods: We extracted the data on 1,099 patients with laboratory-confirmed 2019-nCoV ARD from 552 hospitals in 31 provinces/provincial municipalities through January 29th, 2020. Results: The median age was 47.0 years, and 41.90% were females. Only 1.18% of patients had a direct contact with wildlife, whereas 31.30% had been to Wuhan and 71.80% had contacted with people from Wuhan. Fever (87.9%) and cough (67.7%) were the most common symptoms. Diarrhea is uncommon. The median incubation period was 3.0 days (range, 0 to 24.0 days). On admission, ground-glass opacity was the typical radiological finding on chest computed tomography (50.00%). Significantly more severe cases were diagnosed by symptoms plus reverse-transcriptase polymerase-chain-reaction without abnormal radiological findings than non-severe cases (23.87% vs. 5.20%, P<0.001). Lymphopenia was observed in 82.1% of patients. 55 patients (5.00%) were admitted to intensive care unit and 15 (1.36%) succumbed. Severe pneumonia was independently associated with either the admission to intensive care unit, mechanical ventilation, or death in multivariate competing-risk model (sub-distribution hazards ratio, 9.80; 95% confidence interval, 4.06 to 23.67). Conclusions: The 2019-nCoV epidemic spreads rapidly by human-to-human transmission. Normal radiologic findings are present among some patients with 2019-nCoV infection. The disease severity (including oxygen saturation, respiratory rate, blood leukocyte/lymphocyte count and chest X-ray/CT manifestations) predict poor clinical outcomes.", "date": "2020", "authors": ["Wei-jie Guan", "Zheng-yi Ni", "Yu Hu", "Wen-hua Liang", "Chun-quan Ou", "Jian-xing He", "Lei Liu", "Hong Shan", "Chun-liang Lei", "David Sc Hui", "Bin Du", "Lan-juan Li", "Guang Zeng", "Kowk-Yung Yuen", "Ru-chong Chen", "Chun-li Tang", "Tao Wang", "Ping-yan Chen", "Jie Xiang", "Shi-yue Li", "Jin-lin Wang", "Zi-jing Liang", "Yi-xiang Peng", "Li Wei", "Yong Liu", "Ya-hua Hu", "Peng Peng", "Jian-ming Wang", "Ji-yang Liu", "Zhong Chen", "Gang Li", "Zhi-jian Zheng", "Shao-qin Qiu", "Jie Luo", "Chang-jiang Ye", "Shao-yong Zhu", "Nan-shan Zhong"], "references": ["3007814559", "3013985547", "3013985547", "3010176949", "3010832770", "3009607814", "3009607814", "3007277154", "3006419170"]}, {"id": "2618530766", "title": "ImageNet classification with deep convolutional neural networks", "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.", "date": "2017", "authors": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "references": ["639708223", "2613718673", "2953106684", "2155541015", "2155541015", "2953360861", "2402144811", "2402144811", "2953384591"]}, {"id": "2163605009", "title": "ImageNet Classification with Deep Convolutional Neural Networks", "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.", "date": "2012", "authors": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "references": ["2194775991", "2949650786", "2097117768", "2097117768", "2950179405", "639708223", "639708223", "2613718673", "2953106684"]}, {"id": "639708223", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features\u2014using the recently popular terminology of neural networks with \u2019attention\u2019 mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3] , our detection system has a frame rate of 5 fps ( including all steps ) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.", "date": "2017", "authors": ["Shaoqing Ren", "Kaiming He", "Ross Girshick", "Jian Sun"], "references": ["2963091558", "2963091558", "2770201307", "2962949934", "2117287331", "2117287331", "2952009708", "2343052201", "2343052201"]}, {"id": "2613718673", "title": "Faster R-CNN: towards real-time object detection with region proposal networks", "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [7] and Fast R-CNN [5] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. RPNs are trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. With a simple alternating optimization, RPN and Fast R-CNN can be trained to share convolutional features. For the very deep VGG-16 model [19], our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007 (73.2% mAP) and 2012 (70.4% mAP) using 300 proposals per image. Code is available at https://github.com/ShaoqingRen/faster_rcnn.", "date": "2015", "authors": ["Shaoqing Ren", "Kaiming He", "Ross Girshick", "Jian Sun"], "references": ["2194775991", "2949650786", "3106250896", "3106250896", "2193145675", "2963037989", "2963037989", "1483870316", "2806070179"]}, {"id": "2963341956", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).", "date": "2018", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina N. Toutanova"], "references": ["2970597249", "2970597249", "2950813464", "2911489562", "2964110616", "2964110616", "2911109671", "3035524453", "3035524453"]}, {"id": "2965373594", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "abstract": "Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.", "date": "2019", "authors": ["Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov"], "references": ["2970597249", "2950813464", "2996428491", "2996428491", "2975059944", "3035390927", "3035390927", "2983040767", "3082274269"]}, {"id": "2970597249", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding", "abstract": "With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment setting, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.", "date": "2019", "authors": ["Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime G. Carbonell", "Ruslan Salakhutdinov", "Quoc V. Le"], "references": ["2996035354", "3013571468", "2990704537", "2990704537", "2943552823", "3100307207", "3100307207", "3020712669", "3105966348"]}, {"id": "2963091558", "title": "Non-local Neural Networks", "abstract": "Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method [4] in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our nonlocal models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code will be made available.", "date": "2018", "authors": ["Xiaolong Wang", "Ross Girshick", "Abhinav Gupta", "Kaiming He"], "references": ["2806070179", "2963150697", "2599765304", "2893749619", "2893749619", "2952716587", "2979750740", "2979750740", "2785053089"]}, {"id": "2963858333", "title": "Graph Attention Networks.", "abstract": "", "date": "2018", "authors": ["Petar Velickovic", "Guillem Cucurull", "Arantxa Casanova", "Adriana Romero", "Pietro Li\u00f2", "Yoshua Bengio"], "references": ["2962711740", "2894175828", "3017271475", "2907492528", "2963925437", "2963925437", "2789541106", "2805516822", "2962946486"]}, {"id": "2766453196", "title": "Graph Attention Networks", "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).", "date": "2017", "authors": ["Petar Veli\u010dkovi\u0107", "Guillem Cucurull", "Arantxa Casanova", "Adriana Romero", "Pietro Li\u00f2", "Yoshua Bengio"], "references": ["2979750740", "2785053089", "2963925437", "2963925437", "2789541106", "2798122215", "2798598284", "2809418595", "2809418595"]}, {"id": "2907492528", "title": "A Comprehensive Survey on Graph Neural Networks", "abstract": "Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.", "date": "2020", "authors": ["Zonghan Wu", "Shirui Pan", "Fengwen Chen", "Guodong Long", "Chengqi Zhang", "Philip S. Yu"], "references": ["2988916019", "2890715498", "2905224888", "2916106175", "2986382673", "2986382673", "2944143243", "3007332492", "2990045899"]}, {"id": "2963250244", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing", "abstract": "This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at https://github.com/google/sentencepiece.", "date": "2018", "authors": ["Taku Kudo", "John Richardson"], "references": ["2996428491", "2975059944", "3035390927", "3035390927", "2983040767", "3082274269", "3082274269", "2981852735", "2970279348"]}, {"id": "2963446712", "title": "Densely Connected Convolutional Networks", "abstract": "Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections&#x2014;one between each layer and its subsequent layer&#x2014;our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.", "date": "2017", "authors": ["Gao Huang", "Zhuang Liu", "Laurens van der Maaten", "Kilian Q. Weinberger"], "references": ["2964081807", "2964081807", "2736941579", "2963026768", "2963026768", "2798812533", "2964212410", "2964212410", "2626967530"]}, {"id": "2183341477", "title": "Rethinking the Inception Architecture for Computer Vision", "abstract": "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set.", "date": "2016", "authors": ["Christian Szegedy", "Vincent Vanhoucke", "Sergey Ioffe", "Jon Shlens", "Zbigniew Wojna"], "references": ["3106250896", "2193145675", "2963446712", "2963446712", "2511730936", "2302255633", "2302255633", "2949427019", "2581082771"]}, {"id": "2302255633", "title": "Identity Mappings in Deep Residual Networks", "abstract": "Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62 % error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: https://github.com/KaimingHe/resnet-1k-layers.", "date": "2016", "authors": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "references": ["2963446712", "2511730936", "2412782625", "2412782625", "2952865063", "2963470893", "2963470893", "2523714292", "2592929672"]}, {"id": "2130942839", "title": "Sequence to Sequence Learning with Neural Networks", "abstract": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.", "date": "2014", "authors": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V. Le"], "references": ["2271840356", "1902237438", "1902237438", "2949335953", "1895577753", "1895577753", "2951912364", "1514535095", "2962784628"]}, {"id": "1902237438", "title": "Effective Approaches to Attention-based Neural Machine Translation", "abstract": "An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT\u201915 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1", "date": "2015", "authors": ["Minh-Thang Luong", "Hieu Pham", "Christopher D. Manning"], "references": ["2963403868", "2626778328", "2962784628", "2962784628", "1816313093", "2963216553", "2963216553", "2284660317", "2963212250"]}, {"id": "1895577753", "title": "Show and tell: A neural image caption generator", "abstract": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.", "date": "2015", "authors": ["Oriol Vinyals", "Alexander Toshev", "Samy Bengio", "Dumitru Erhan"], "references": ["2481240925", "2481240925", "1905882502", "2951805548", "3102564565", "3102564565", "2962858109", "2616247523", "1933349210"]}, {"id": "3011508296", "title": "Critical Care Utilization for the COVID-19 Outbreak in Lombardy, Italy: Early Experience and Forecast During an Emergency Response.", "abstract": "", "date": "2020", "authors": ["Giacomo Grasselli", "2", "1,", "Maurizio Cecconi"], "references": ["3012925204", "3013816672", "3014524604", "3014524604", "3013042152", "3018450694", "3014604938", "3033453353", "3024193040"]}, {"id": "3013967887", "title": "Estimates of the severity of coronavirus disease 2019: a model-based analysis.", "abstract": "Background In the face of rapidly changing data, a range of case fatality ratio estimates for coronavirus disease 2019 (COVID-19) have been produced that differ substantially in magnitude. We aimed to provide robust estimates, accounting for censoring and ascertainment biases. Methods We collected individual-case data for patients who died from COVID-19 in Hubei, mainland China (reported by national and provincial health commissions to Feb 8, 2020), and for cases outside of mainland China (from government or ministry of health websites and media reports for 37 countries, as well as Hong Kong and Macau, until Feb 25, 2020). These individual-case data were used to estimate the time between onset of symptoms and outcome (death or discharge from hospital). We next obtained age-stratified estimates of the case fatality ratio by relating the aggregate distribution of cases to the observed cumulative deaths in China, assuming a constant attack rate by age and adjusting for demography and age-based and location-based under-ascertainment. We also estimated the case fatality ratio from individual line-list data on 1334 cases identified outside of mainland China. Using data on the prevalence of PCR-confirmed cases in international residents repatriated from China, we obtained age-stratified estimates of the infection fatality ratio. Furthermore, data on age-stratified severity in a subset of 3665 cases from China were used to estimate the proportion of infected individuals who are likely to require hospitalisation. Findings Using data on 24 deaths that occurred in mainland China and 165 recoveries outside of China, we estimated the mean duration from onset of symptoms to death to be 17\u00b78 days (95% credible interval [CrI] 16\u00b79-19\u00b72) and to hospital discharge to be 24\u00b77 days (22\u00b79-28\u00b71). In all laboratory confirmed and clinically diagnosed cases from mainland China (n=70 117), we estimated a crude case fatality ratio (adjusted for censoring) of 3\u00b767% (95% CrI 3\u00b756-3\u00b780). However, after further adjusting for demography and under-ascertainment, we obtained a best estimate of the case fatality ratio in China of 1\u00b738% (1\u00b723-1\u00b753), with substantially higher ratios in older age groups (0\u00b732% [0\u00b727-0\u00b738] in those aged Interpretation These early estimates give an indication of the fatality ratio across the spectrum of COVID-19 disease and show a strong age gradient in risk of death. Funding UK Medical Research Council.", "date": "2020", "authors": ["Robert Verity", "Lucy C Okell", "Ilaria Dorigatti", "Peter Winskill", "Charles Whittaker", "Natsuko Imai", "Gina Cuomo-Dannenburg", "Hayley Thompson", "Patrick G T Walker", "Han Fu", "Amy Dighe", "Jamie T Griffin", "Marc Baguelin", "Sangeeta Bhatia", "Adhiratha Boonyasiri", "Anne Cori", "Zulma Cucunub\u00e1", "Rich FitzJohn", "Katy Gaythorpe", "Will Green", "Arran Hamlet", "Wes Hinsley", "Daniel Laydon", "Gemma Nedjati-Gilani", "Steven Riley", "Sabine van Elsland", "Erik Volz", "Haowei Wang", "Yuanrong Wang", "Xiaoyue Xi", "Christl A Donnelly", "3", "1", "1"], "references": ["3013215798", "3011466591", "3042270788", "3026764413", "3025090814", "3025090814", "3016897431", "3032971139", "3035189381"]}, {"id": "3016127017", "title": "Neurologic Manifestations of Hospitalized Patients With Coronavirus Disease 2019 in Wuhan, China.", "abstract": "Importance The outbreak of coronavirus disease 2019 (COVID-19) in Wuhan, China, is serious and has the potential to become an epidemic worldwide. Several studies have described typical clinical manifestations including fever, cough, diarrhea, and fatigue. However, to our knowledge, it has not been reported that patients with COVID-19 had any neurologic manifestations. Objective To study the neurologic manifestations of patients with COVID-19. Design, Setting, and Participants This is a retrospective, observational case series. Data were collected from January 16, 2020, to February 19, 2020, at 3 designated special care centers for COVID-19 (Main District, West Branch, and Tumor Center) of the Union Hospital of Huazhong University of Science and Technology in Wuhan, China. The study included 214 consecutive hospitalized patients with laboratory-confirmed diagnosis of severe acute respiratory syndrome coronavirus 2 infection. Main Outcomes and Measures Clinical data were extracted from electronic medical records, and data of all neurologic symptoms were checked by 2 trained neurologists. Neurologic manifestations fell into 3 categories: central nervous system manifestations (dizziness, headache, impaired consciousness, acute cerebrovascular disease, ataxia, and seizure), peripheral nervous system manifestations (taste impairment, smell impairment, vision impairment, and nerve pain), and skeletal muscular injury manifestations. Results Of 214 patients (mean [SD] age, 52.7 [15.5] years; 87 men [40.7%]) with COVID-19, 126 patients (58.9%) had nonsevere infection and 88 patients (41.1%) had severe infection according to their respiratory status. Overall, 78 patients (36.4%) had neurologic manifestations. Compared with patients with nonsevere infection, patients with severe infection were older, had more underlying disorders, especially hypertension, and showed fewer typical symptoms of COVID-19, such as fever and cough. Patients with more severe infection had neurologic manifestations, such as acute cerebrovascular diseases (5 [5.7%] vs 1 [0.8%]), impaired consciousness (13 [14.8%] vs 3 [2.4%]), and skeletal muscle injury (17 [19.3%] vs 6 [4.8%]). Conclusions and Relevance Patients with COVID-19 commonly have neurologic manifestations. During the epidemic period of COVID-19, when seeing patients with neurologic manifestations, clinicians should suspect severe acute respiratory syndrome coronavirus 2 infection as a differential diagnosis to avoid delayed diagnosis or misdiagnosis and lose the chance to treat and prevent further transmission.", "date": "2019", "authors": ["Ling Mao", "Huijuan Jin", "Mengdie Wang", "Yu Hu", "Shengcai Chen", "Quanwei He", "Jiang Chang", "Candong Hong", "Yifan Zhou", "David Wang", "Xiaoping Miao", "Yanan Li", "Bo Hu"], "references": ["3015197879", "3097167529", "3017271475", "3024790435", "3041319886", "3025282583", "3013556081", "3040801404", "3028162226"]}, {"id": "3015863623", "title": "Incidence of thrombotic complications in critically ill ICU patients with COVID-19.", "abstract": "Abstract Introduction COVID-19 may predispose to both venous and arterial thromboembolism due to excessive inflammation, hypoxia, immobilisation and diffuse intravascular coagulation. Reports on the incidence of thrombotic complications are however not available. Methods We evaluated the incidence of the composite outcome of symptomatic acute pulmonary embolism (PE), deep-vein thrombosis, ischemic stroke, myocardial infarction or systemic arterial embolism in all COVID-19 patients admitted to the ICU of 2 Dutch university hospitals and 1 Dutch teaching hospital. Results We studied 184 ICU patients with proven COVID-19 pneumonia of whom 23 died (13%), 22 were discharged alive (12%) and 139 (76%) were still on the ICU on April 5th 2020. All patients received at least standard doses thromboprophylaxis. The cumulative incidence of the composite outcome was 31% (95%CI 20-41), of which CTPA and/or ultrasonography confirmed VTE in 27% (95%CI 17-37%) and arterial thrombotic events in 3.7% (95%CI 0-8.2%). PE was the most frequent thrombotic complication (n = 25, 81%). Age (adjusted hazard ratio (aHR) 1.05/per year, 95%CI 1.004-1.01) and coagulopathy, defined as spontaneous prolongation of the prothrombin time > 3 s or activated partial thromboplastin time > 5 s (aHR 4.1, 95%CI 1.9-9.1), were independent predictors of thrombotic complications. Conclusion The 31% incidence of thrombotic complications in ICU patients with COVID-19 infections is remarkably high. Our findings reinforce the recommendation to strictly apply pharmacological thrombosis prophylaxis in all COVID-19 patients admitted to the ICU, and are strongly suggestive of increasing the prophylaxis towards high-prophylactic doses, even in the absence of randomized evidence.", "date": "2020", "authors": ["F.A. Klok", "M.J.H.A. Kruip", "N.J.M. van der Meer", "M.S. Arbous", "D.A.M.P.J. Gommers", "K.M. Kant", "F.H.J. Kaptein", "J. van Paassen", "M.A.M. Stals", "M.V. Huisman", "H. Endeman"], "references": ["3017326650", "3010848803", "3019953082", "3021591080", "3024790435", "3014448531", "3017014626", "3041319886", "3023873927", "3027754404"]}, {"id": "3012756997", "title": "Temporal profiles of viral load in posterior oropharyngeal saliva samples and serum antibody responses during infection by SARS-CoV-2: an observational cohort study.", "abstract": "Summary Background Coronavirus disease 2019 (COVID-19) causes severe community and nosocomial outbreaks. Comprehensive data for serial respiratory viral load and serum antibody responses from patients infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) are not yet available. Nasopharyngeal and throat swabs are usually obtained for serial viral load monitoring of respiratory infections but gathering these specimens can cause discomfort for patients and put health-care workers at risk. We aimed to ascertain the serial respiratory viral load of SARS-CoV-2 in posterior oropharyngeal (deep throat) saliva samples from patients with COVID-19, and serum antibody responses. Methods We did a cohort study at two hospitals in Hong Kong. We included patients with laboratory-confirmed COVID-19. We obtained samples of blood, urine, posterior oropharyngeal saliva, and rectal swabs. Serial viral load was ascertained by reverse transcriptase quantitative PCR (RT-qPCR). Antibody levels against the SARS-CoV-2 internal nucleoprotein (NP) and surface spike protein receptor binding domain (RBD) were measured using EIA. Whole-genome sequencing was done to identify possible mutations arising during infection. Findings Between Jan 22, 2020, and Feb 12, 2020, 30 patients were screened for inclusion, of whom 23 were included (median age 62 years [range 37\u201375]). The median viral load in posterior oropharyngeal saliva or other respiratory specimens at presentation was 5\u00b72 log10 copies per mL (IQR 4\u00b71\u20137\u00b70). Salivary viral load was highest during the first week after symptom onset and subsequently declined with time (slope \u22120\u00b715, 95% CI \u22120\u00b719 to \u22120\u00b711; R2=0\u00b771). In one patient, viral RNA was detected 25 days after symptom onset. Older age was correlated with higher viral load (Spearman's \u03c1=0\u00b748, 95% CI 0\u00b7074\u20130\u00b775; p=0\u00b7020). For 16 patients with serum samples available 14 days or longer after symptom onset, rates of seropositivity were 94% for anti-NP IgG (n=15), 88% for anti-NP IgM (n=14), 100% for anti-RBD IgG (n=16), and 94% for anti-RBD IgM (n=15). Anti-SARS-CoV-2-NP or anti-SARS-CoV-2-RBD IgG levels correlated with virus neutralisation titre (R2>0\u00b79). No genome mutations were detected on serial samples. Interpretation Posterior oropharyngeal saliva samples are a non-invasive specimen more acceptable to patients and health-care workers. Unlike severe acute respiratory syndrome, patients with COVID-19 had the highest viral load near presentation, which could account for the fast-spreading nature of this epidemic. This finding emphasises the importance of stringent infection control and early use of potent antiviral agents, alone or in combination, for high-risk individuals. Serological assay can complement RT-qPCR for diagnosis. Funding Richard and Carol Yu, May Tam Mak Mei Yin, The Shaw Foundation Hong Kong, Michael Tong, Marina Lee, Government Consultancy Service, and Sanming Project of Medicine.", "date": "2020", "authors": ["Kelvin Kai Wang To", "2", "3", "3", "4", "5", "6", "2", "2", "3", "3", "3", "3", "2", "2", "2", "2", "2", "2", "2", "2", "1,", "Ivan Fan Ngai Hung", "Zhiwei Chen", "Honglin Chen", "Kwok Yung Yuen"], "references": ["3015571324", "3011322620", "3019291397", "3042270788", "3019171825", "3021274772", "3040552450", "3014281460", "3016053819"]}, {"id": "3010951319", "title": "SARS-CoV-2 Infection in Children.", "abstract": "SARS-CoV-2 Infection in Children In this report, investigators in Wuhan, China, describe the spectrum of Covid-19 illness in children under the age of 16 years. Of 1391 children assessed and tested...", "date": "2020", "authors": ["Xiaoxia Lu", "Liqiong Zhang", "Hui Du", "Jingjing Zhang", "Yuan Y. Li", "Jingyu Qu", "Wenxin Zhang", "Youjie Wang", "Shuangshuang Bao", "Ying Li", "Chuansha Wu", "Hongxiu Liu", "Di Liu", "Jianbo Shao", "Xuehua Peng", "Yonghong Yang", "Zhisheng Liu", "Yun Xiang", "Furong Zhang", "Rona M. Silva", "Kent E. Pinkerton", "Kunling Shen", "Han Xiao", "Shunqing Xu", "Gary W.K. Wong"], "references": ["3013215798", "3011466591", "3012797451", "3014361632", "3016489853", "3016489853", "3013568541", "3020239101", "3020239101"]}, {"id": "3013215798", "title": "Quantifying SARS-CoV-2 transmission suggests epidemic control with digital contact tracing.", "abstract": "The newly emergent human virus SARS-CoV-2 (severe acute respiratory syndrome-coronavirus 2) is resulting in high fatality rates and incapacitated health systems. Preventing further transmission is a priority. We analyzed key parameters of epidemic spread to estimate the contribution of different transmission routes and determine requirements for case isolation and contact tracing needed to stop the epidemic. Although SARS-CoV-2 is spreading too fast to be contained by manual contact tracing, it could be controlled if this process were faster, more efficient, and happened at scale. A contact-tracing app that builds a memory of proximity contacts and immediately notifies contacts of positive cases can achieve epidemic control if used by enough people. By targeting recommendations to only those at risk, epidemics could be contained without resorting to mass quarantines (\"lockdowns\") that are harmful to society. We discuss the ethical requirements for an intervention of this kind.", "date": "2020", "authors": ["Luca Ferretti", "Chris Wymant", "Michelle Kendall", "Lele Zhao", "Anel Nurtay", "Lucie Abeler-D\u00f6rner", "Michael Parker", "David Bonsall", "Christophe Fraser"], "references": ["3015840999", "3019643748", "3035706118", "3034825141", "3023242899", "3036030877", "3036030877", "3007083252", "3019051739"]}, {"id": "3011466591", "title": "Quantifying dynamics of SARS-CoV-2 transmission suggests that epidemic control and avoidance is feasible through instantaneous digital contact tracing", "abstract": "Mobile phone apps implementing algorithmic contact tracing can speed up the process of tracing newly diagnosed individuals, spreading information instantaneously back through a past contact network to inform them that they are at risk of being infected, and thus allow them to take appropriate social distancing and testing measures. The aim of non-pharmaceutical infection prevention is to move a population towards herd protection, a state where a population maintains R0", "date": "2020", "authors": ["L Ferretti", "C Wymant", "M Kendall", "L Zhao", "A Nurtay", "D G Bonsall", "C Fraser"], "references": ["3013215798", "3011466591", "3012708458", "3093794992", "3097795338", "3097795338", "3035711606", "3014633126", "3013067383"]}, {"id": "3007814559", "title": "Clinical characteristics of 140 patients infected with SARS-CoV-2 in Wuhan, China.", "abstract": "Background Coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection has been widely spread. We aim to investigate the clinical characteristic and allergy status of patients infected with SARS-CoV-2. Methods Electronic medical records including demographics, clinical manifestation, comorbidities, laboratory data, and radiological materials of 140 hospitalized COVID-19 patients, with confirmed result of SARS-CoV-2 viral infection, were extracted and analyzed. Results An approximately 1:1 ratio of male (50.7%) and female COVID-19 patients was found, with an overall median age of 57.0 years. All patients were community-acquired cases. Fever (91.7%), cough (75.0%), fatigue (75.0%), and gastrointestinal symptoms (39.6%) were the most common clinical manifestations, whereas hypertension (30.0%) and diabetes mellitus (12.1%) were the most common comorbidities. Drug hypersensitivity (11.4%) and urticaria (1.4%) were self-reported by several patients. Asthma or other allergic diseases were not reported by any of the patients. Chronic obstructive pulmonary disease (COPD, 1.4%) patients and current smokers (1.4%) were rare. Bilateral ground-glass or patchy opacity (89.6%) was the most common sign of radiological finding. Lymphopenia (75.4%) and eosinopenia (52.9%) were observed in most patients. Blood eosinophil counts correlate positively with lymphocyte counts in severe (r = .486, P Conclusion Detailed clinical investigation of 140 hospitalized COVID-19 cases suggests eosinopenia together with lymphopenia may be a potential indicator for diagnosis. Allergic diseases, asthma, and COPD are not risk factors for SARS-CoV-2 infection. Older age, high number of comorbidities, and more prominent laboratory abnormalities were associated with severe patients.", "date": "2020", "authors": ["Jin-jin Zhang", "Xiang Dong", "Yi-yuan Cao", "Ya-dong Yuan", "Yi-bin Yang", "You-qin Yan", "Cezmi A. Akdis", "Ya-dong Gao"], "references": ["3009799538", "3023787531", "3018949454", "3015696390", "3011045397", "3025614942", "3014007058", "3020512604", "3020512604", "3007165215", "3014486521"]}, {"id": "3013985547", "title": "Antibody responses to SARS-CoV-2 in patients of novel coronavirus disease 2019", "abstract": "Background The novel coronavirus SARS-CoV-2 is a newly emerging virus. The antibody response in infected patient remains largely unknown, and the clinical values of antibody testing have not been fully demonstrated. Methods A total of 173 patients with SARS-CoV-2 infection were enrolled. Their serial plasma samples (n=535) collected during the hospitalization were tested for total antibodies (Ab), IgM and IgG against SARS-CoV-2. The dynamics of antibodies with the disease progress was analyzed. Results Among 173 patients, the seroconversion rate for Ab, IgM and IgG was 93.1%, 82.7% and 64.7%, respectively. The reason for the negative antibody findings in 12 patients might due to the lack of blood samples at the later stage of illness. The median seroconversion time for Ab, IgM and then IgG were day-11, day-12 and day-14, separately. The presence of antibodies was Conclusions The antibody detection offers vital clinical information during the course of SARS-CoV-2 infection. The findings provide strong empirical support for the routine application of serological testing in the diagnosis and management of COVID-19 patients.", "date": "2020", "authors": ["Juanjuan Zhao", "Quan Yuan", "Haiyan Wang", "Wei Liu", "Xuejiao Liao", "Yingying Su", "Xin Wang", "Jing Yuan", "Tingdong Li", "Jinxiu Li", "Shen Qian", "Congming Hong", "Fuxiang Wang", "Yingxia Liu", "Zhaoqin Wang", "Qing He", "Zhiyong Li", "Bin He", "Tianying Zhang", "Yang Fu", "Shengxiang Ge", "Lei Liu", "Jun Zhang", "Ningshao Xia", "Zheng Zhang"], "references": ["3032971139", "3040552450", "3024506939", "3041319886", "3015321334", "3022878099", "3025391403", "3082342835", "3016437870", "3033368763"]}, {"id": "3010832770", "title": "Coronavirus Disease 2019 (COVID-19): Emerging and Future Challenges for Dental and Oral Medicine.", "abstract": "The epidemic of coronavirus disease 2019 (COVID-19), originating in Wuhan, China, has become a major public health challenge for not only China but also countries around the world. The World Health Organization announced that the outbreaks of the novel coronavirus have constituted a public health emergency of international concern. As of February 26, 2020, COVID-19 has been recognized in 34 countries, with a total of 80,239 laboratory-confirmed cases and 2,700 deaths. Infection control measures are necessary to prevent the virus from further spreading and to help control the epidemic situation. Due to the characteristics of dental settings, the risk of cross infection can be high between patients and dental practitioners. For dental practices and hospitals in areas that are (potentially) affected with COVID-19, strict and effective infection control protocols are urgently needed. This article, based on our experience and relevant guidelines and research, introduces essential knowledge about COVID-19 and nosocomial infection in dental settings and provides recommended management protocols for dental practitioners and students in (potentially) affected areas.", "date": "2020", "authors": ["L. Meng", "F. Hua", "Z. Bian"], "references": ["3015563505", "3014791548", "3017814684", "3015633728", "3015776255", "3025090567", "3017289882", "3016379792", "3014654720", "3011736640"]}, {"id": "3009607814", "title": "Clinical characteristics of 24 asymptomatic infections with COVID-19 screened among close contacts in Nanjing, China.", "abstract": "Previous studies have showed clinical characteristics of patients with the 2019 novel coronavirus disease (COVID-19) and the evidence of person-to-person transmission. Limited data are available for asymptomatic infections. This study aims to present the clinical characteristics of 24 cases with asymptomatic infection screened from close contacts and to show the transmission potential of asymptomatic COVID-19 virus carriers. Epidemiological investigations were conducted among all close contacts of COVID-19 patients (or suspected patients) in Nanjing, Jiangsu Province, China, from Jan 28 to Feb 9, 2020, both in clinic and in community. Asymptomatic carriers were laboratory-confirmed positive for the COVID-19 virus by testing the nucleic acid of the pharyngeal swab samples. Their clinical records, laboratory assessments, and chest CT scans were reviewed. As a result, none of the 24 asymptomatic cases presented any obvious symptoms while nucleic acid screening. Five cases (20.8%) developed symptoms (fever, cough, fatigue, etc.) during hospitalization. Twelve (50.0%) cases showed typical CT images of ground-glass chest and 5 (20.8%) presented stripe shadowing in the lungs. The remaining 7 (29.2%) cases showed normal CT image and had no symptoms during hospitalization. These 7 cases were younger (median age: 14.0 years; P=0.012) than the rest. None of the 24 cases developed severe COVID-19 pneumonia or died. The median communicable period, defined as the interval from the first day of positive nucleic acid tests to the first day of continuous negative tests, was 9.5 days (up to 21 days among the 24 asymptomatic cases). Through epidemiological investigation, we observed a typical asymptomatic transmission to the cohabiting family members, which even caused severe COVID-19 pneumonia. Overall, the asymptomatic carriers identified from close contacts were prone to be mildly ill during hospitalization. However, the communicable period could be up to three weeks and the communicated patients could develop severe illness. These results highlighted the importance of close contact tracing and longitudinally surveillance via virus nucleic acid tests. Further isolation recommendation and continuous nucleic acid tests may also be recommended to the patients discharged.", "date": "2020", "authors": ["Zhiliang Hu", "2", "1", "2", "1", "2", "1", "1", "2", "1", "2", "1", "2", "2", "1"], "references": []}, {"id": "3007277154", "title": "Clinical Characteristics of 24 Asymptomatic Infections with COVID-19 Screened among Close Contacts in Nanjing, China", "abstract": "Background: Previous studies have showed clinical characteristics of patients with the 2019 novel coronavirus disease (COVID-19) and the evidence of person-to-person transmission. Limited data are available for asymptomatic infections. This study aims to present the clinical characteristics of 24 cases with asymptomatic infection screened from close contacts and to show the transmission potential of asymptomatic COVID-19 virus carriers. Methods: Epidemiological investigations were conducted among all close contacts of COVID-19 patients (or suspected patients) in Nanjing, Jiangsu Province, China, from Jan 28 to Feb 9, 2020, both in clinic and in community. Asymptomatic carriers were laboratory-confirmed positive for the COVID-19 virus by testing the nucleic acid of the pharyngeal swab samples. Their clinical records, laboratory assessments, and chest CT scans were reviewed. Findings: None of the 24 asymptomatic cases presented any obvious symptoms before nucleic acid screening. Five cases (20.8%) developed symptoms (fever, cough, fatigue and etc.) during hospitalization. Twelve (50.0%) cases showed typical CT images of ground-glass chest and five (20.8%) presented stripe shadowing in the lungs. The remaining seven (29.2%) cases showed normal CT image and had no symptoms during hospitalization. These seven cases were younger (median age: 14.0 years; P = 0.012) than the rest. None of the 24 cases developed severe COVID-19 pneumonia or died. The median communicable period, defined as the interval from the first day of positive nucleic acid tests to the first day of continuous negative tests, was 9.5 days (up to 21 days among the 24 asymptomatic cases). Through epidemiological investigation, we observed a typical asymptomatic transmission to the cohabiting family members, which even caused severe COVID-19 pneumonia. Interpretation: The asymptomatic carriers identified from close contacts were prone to be mildly ill during hospitalization. However, the communicable period could be up to three weeks and the communicated patients could develop severe illness. These results highlighted the importance of close contact tracing and longitudinally surveillance via virus nucleic acid tests. Further isolation recommendation and continuous nucleic acid tests may also be recommended to the patients discharged.", "date": "2020", "authors": ["Zhiliang Hu", "Ci Song", "Chuanjun Xu", "Guangfu Jin", "Yaling Chen", "Xin Xu", "Hongxia Ma", "Wei Chen", "Yuan Lin", "Yishan Zheng", "Jianming Wang", "zhibin hu", "Yongxiang Yi", "Hongbing Shen"], "references": ["3013963899", "3048792788", "3030138173", "3016574080", "3092114493", "3089216256"]}, {"id": "3006419170", "title": "The COVID-19 epidemic.", "abstract": "", "date": "2020", "authors": ["Thirumalaisamy P. Velavan", "Christian G. Meyer"], "references": ["3018782651", "3010377921", "3011038311", "3034593359", "3006839750", "3020247120", "3012883833", "3036373129", "3005879071", "3013573204"]}, {"id": "2155541015", "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition", "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.", "date": "2014", "authors": ["Jeff Donahue", "Yangqing Jia", "Oriol Vinyals", "Judy Hoffman", "Ning Zhang", "Eric Tzeng", "Trevor Darrell"], "references": ["2102605133", "2951638509", "1903029394", "1903029394", "2952632681", "2155893237", "2155893237", "2950094539", "2963037989"]}, {"id": "2402144811", "title": "TensorFlow: a system for large-scale machine learning", "abstract": "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.", "date": "2016", "authors": ["Mart\u00edn Abadi", "Paul Barham", "Jianmin Chen", "Zhifeng Chen", "Andy Davis", "Jeffrey Dean", "Matthieu Devin", "Sanjay Ghemawat", "Geoffrey Irving", "Michael Isard", "Manjunath Kudlur", "Josh Levenberg", "Rajat Monga", "Sherry Moore", "Derek G. Murray", "Benoit Steiner", "Paul Tucker", "Vijay Vasudevan", "Pete Warden", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng"], "references": []}, {"id": "2953384591", "title": "TensorFlow: A system for large-scale machine learning", "abstract": "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.", "date": "2016", "authors": ["Mart\u00edn Abadi", "Paul Barham", "Jianmin Chen", "Zhifeng Chen", "Andy Davis", "Jeffrey Dean", "Matthieu Devin", "Sanjay Ghemawat", "Geoffrey Irving", "Michael Isard", "Manjunath Kudlur", "Josh Levenberg", "Rajat Monga", "Sherry Moore", "Derek G. Murray", "Benoit Steiner", "Paul Tucker", "Vijay Vasudevan", "Pete Warden", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng"], "references": ["2893749619", "2952716587", "2550821151", "2550821151", "2951184134", "2982138961", "2982138961", "2616028256", "3100935330"]}, {"id": "2097117768", "title": "Going deeper with convolutions", "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.", "date": "2015", "authors": ["Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich"], "references": ["2194775991", "2949650786", "2618530766", "2618530766", "2163605009", "639708223", "639708223", "2613718673", "2953106684"]}, {"id": "2950179405", "title": "Going Deeper with Convolutions", "abstract": "We propose a deep convolutional neural network architecture codenamed \"Inception\", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.", "date": "2014", "authors": ["Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich"], "references": ["2962835968", "1686810756", "1836465849", "1836465849", "2949117887", "2117539524", "2117539524", "2952020226", "1903029394"]}]}